<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-type" content="text/html; charset=iso-8859-1">
<title>Replication Features of a ZFS Storage Pool - Solaris ZFS Administration Guide</title>
<meta name="robots" content="index,follow">
<meta name="robots" content="index,follow">
<meta name="date" content="2008-01-01">
<meta name="collection" content="reference">
<link rel="stylesheet" type="text/css" href="css/elements.css">
<link rel="stylesheet" type="text/css" href="css/indiana.css">
</head>

<body>


<div class="Masthead">
   <div class="MastheadLogo"></div>
   <div class="Title">Solaris ZFS Administration Guide</div>
</div>

<table class="Layout" border="0" cellspacing="0" width="100%">
<tbody>

   <tr valign="top" class="PageControls">
      <td></td>
      <td>
         <table width="100%">
      	   <tr>
      	     <td>
                 <a href="gcfog.html">Previous</a>
             </td>
             <td align="right">
                 <a href="gaypw.html">Next</a>
             </td>
           </tr>
         </table>
      </td>
   </tr>
   
   <tr valign="top">
      <td class="Navigation" width="200px"><p class="toc level1"><a href="docinfo.html">Document Information</a></p>
<p class="toc level1 tocsp"><a href="preface-1.html">Preface</a></p>
<p class="toc level1 tocsp"><a href="zfsover-1.html">1.&nbsp;&nbsp;Solaris ZFS File System (Introduction)</a></p>
<p class="toc level1 tocsp"><a href="setup-1.html">2.&nbsp;&nbsp;Getting Started With ZFS</a></p>
<p class="toc level1 tocsp"><a href="gbcik.html">3.&nbsp;&nbsp;ZFS and Traditional File System Differences</a></p>
<p class="toc level1 tocsp"><a href="gavwn.html">4.&nbsp;&nbsp;Managing ZFS Storage Pools</a></p>
<p class="toc level2"><a href="gcfog.html">Components of a ZFS Storage Pool</a></p>
<div class="onpage">
<p class="toc level2"><a href="">Replication Features of a ZFS Storage Pool</a></p>
</div>
<p class="toc level2"><a href="gaypw.html">Creating and Destroying ZFS Storage Pools</a></p>
<p class="toc level2"><a href="gayrd.html">Managing Devices in ZFS Storage Pools</a></p>
<p class="toc level2"><a href="gfifk.html">Managing ZFS Storage Pool Properties</a></p>
<p class="toc level2"><a href="gaynp.html">Querying ZFS Storage Pool Status</a></p>
<p class="toc level2"><a href="gbchy.html">Migrating ZFS Storage Pools</a></p>
<p class="toc level1 tocsp"><a href="gavwq.html">5.&nbsp;&nbsp;Managing ZFS File Systems</a></p>
<p class="toc level1 tocsp"><a href="gavvx.html">6.&nbsp;&nbsp;Working With ZFS Snapshots and Clones</a></p>
<p class="toc level1 tocsp"><a href="ftyxi.html">7.&nbsp;&nbsp;Using ACLs to Protect ZFS Files</a></p>
<p class="toc level1 tocsp"><a href="gbchv.html">8.&nbsp;&nbsp;ZFS Delegated Administration</a></p>
<p class="toc level1 tocsp"><a href="ftyxh.html">9.&nbsp;&nbsp;ZFS Advanced Topics</a></p>
<p class="toc level1 tocsp"><a href="gavwg.html">10.&nbsp;&nbsp;ZFS Troubleshooting and Data Recovery</a></p>
<p class="toc level1 tocsp"><a href="idx-1.html">Index</a></p>
</td>
      <td class="ContentPane" width="705px">

	 <div class="MainContent">      	 
             

<a name="gcfof"></a><h3>Replication Features of a ZFS Storage Pool</h3>
<p>ZFS provides data redundancy, as well as self-healing properties, in a mirrored and
a RAID-Z configuration.<a name="indexterm-100"></a></p>
<ul><li><p><a href="#gamss">Mirrored Storage Pool Configuration</a></p></li>
<li><p><a href="#gamtu">RAID-Z Storage Pool Configuration</a></p></li>
<li><p><a href="#gazch">Self-Healing Data in a Redundant Configuration</a></p></li>
<li><p><a href="#gazdd">Dynamic Striping in a Storage Pool</a></p></li></ul>


<a name="gamss"></a><h4>Mirrored Storage Pool Configuration</h4>
<p>A mirrored storage pool configuration requires at least two disks, preferably on separate
controllers. Many disks can be used in a mirrored configuration. In addition, you
can create more than one mirror in each pool. Conceptually, a simple mirrored
configuration would look similar to the following:<a name="indexterm-101"></a><a name="indexterm-102"></a><a name="indexterm-103"></a><a name="indexterm-104"></a></p><pre>mirror c1t0d0 c2t0d0</pre><p>Conceptually, a more complex mirrored configuration would look similar to the following:</p><pre>mirror c1t0d0 c2t0d0 c3t0d0 mirror c4t0d0 c5t0d0 c6t0d0</pre><p>For information about creating a mirrored storage pool, see <a href="gaypw.html#gazhv">Creating a Mirrored Storage Pool</a>.</p>

<a name="gamtu"></a><h4>RAID-Z Storage Pool Configuration</h4>
<p>In addition to a mirrored storage pool configuration, ZFS provides a RAID-Z configuration
with either single or double parity fault tolerance. Single-parity RAID-Z is similar to
RAID-5. Double-parity RAID-Z is similar to RAID-6.<a name="indexterm-105"></a><a name="indexterm-106"></a><a name="indexterm-107"></a><a name="indexterm-108"></a><a name="indexterm-109"></a></p><p>All traditional RAID-5-like algorithms (RAID-4. RAID-5. RAID-6, RDP, and EVEN-ODD, for example) suffer
from a problem known as the &ldquo;RAID-5 write hole.&rdquo; If only part of
a RAID-5 stripe is written, and power is lost before all blocks have
made it to disk, the parity will remain out of sync with the
data, and therefore useless, forever (unless a subsequent full-stripe write overwrites it). In
RAID-Z, ZFS uses variable-width RAID stripes so that all writes are full-stripe writes.
This design is only possible because ZFS integrates file system and device management
in such a way that the file system's metadata has enough information about
the underlying data redundancy model to handle variable-width RAID stripes. RAID-Z is the
world's first software-only solution to the RAID-5 write hole.</p><p>You need at least two disks for a RAID-Z configuration. Otherwise, no special
hardware is required to create a RAID-Z configuration. Currently, RAID-Z provides single parity. For
example, if you have three disks in a RAID-Z configuration, parity data occupies
space equal to one of the three disks. </p><p>A RAID-Z configuration with N disks of size X with P parity
disks can hold approximately (N-P)*X bytes and can withstand P device(s) failing before data
integrity is compromised.  You need at least two disks for a
single-parity RAID-Z configuration and at least three disks for a double-parity RAID-Z configuration. For
example, if you have three disks in a single-parity RAID-Z configuration, parity data
occupies space equal to one of the three disks. Otherwise, no special hardware
is required to create a RAID-Z configuration. </p><p>Conceptually, a RAID-Z configuration with three disks would look similar to the following:</p><pre>raidz c1t0d0 c2t0d0 c3t0d0</pre><p>A more complex conceptual RAID-Z configuration would look similar to the following:</p><pre>raidz c1t0d0 c2t0d0 c3t0d0 c4t0d0 c5t0d0 c6t0d0 c7t0d0 raidz c8t0d0 c9t0d0 c10t0d0 c11t0d0
c12t0d0 c13t0d0 c14t0d0</pre><p>If you are creating a RAID-Z configuration with many disks, as in
this example, a RAID-Z configuration with 14 disks is better split into a
two 7-disk groupings. RAID-Z configurations with single-digit groupings of disks should perform better.</p><p>For information about creating a RAID-Z storage pool, see <a href="gaypw.html#gcvjg">Creating RAID-Z Storage Pools</a>.</p><p>For more information about choosing between a mirrored configuration or a RAID-Z configuration
based on performance and space considerations, see the following blog:</p><p><a href="http://blogs.sun.com/roller/page/roch?entry=when_to_and_not_to">http://blogs.sun.com/roller/page/roch?entry=when_to_and_not_to</a></p><p>For additional information on RAID-Z storage pool recommendations, see the ZFS best practices
site:</p><p><a href="http://www.solarisinternals.com/wiki/index.php/ZFS_Best_Practices_Guide">http://www.solarisinternals.com/wiki/index.php/ZFS_Best_Practices_Guide</a></p>

<a name="gazch"></a><h4>Self-Healing Data in a Redundant Configuration</h4>
<p>ZFS provides for self-healing data in a mirrored or RAID-Z configuration.</p><p>When a bad data block is detected, not only does ZFS fetch
the correct data from another redundant copy, but it also repairs the bad
data by replacing it with the good copy.<a name="indexterm-110"></a></p>

<a name="gazdd"></a><h4>Dynamic Striping in a Storage Pool</h4>
<p>For each virtual device that is added to the pool, ZFS dynamically
stripes data across all available devices. The decision about where to place data is
done at write time, so no fixed width stripes are created at
allocation time.<a name="indexterm-111"></a><a name="indexterm-112"></a><a name="indexterm-113"></a></p><p>When virtual devices are added to a pool, ZFS gradually allocates data to
the new device in order to maintain performance and space allocation policies. Each
virtual device can also be a mirror or a RAID-Z device that
contains other disk devices or files. This configuration allows for flexibility in controlling the
fault characteristics of your pool. For example, you could create the following configurations
out of 4 disks:</p>
<ul><li><p>Four disks using dynamic striping</p></li>
<li><p>One four-way RAID-Z configuration</p></li>
<li><p>Two two-way mirrors using dynamic striping</p></li></ul>
<p>While ZFS supports combining different types of virtual devices within the same pool,
this practice is not recommended. For example, you can create a pool with
a two-way mirror and a three-way RAID-Z configuration. However, your fault tolerance is
as good as your worst virtual device, RAID-Z in this case. The recommended
practice is to use top-level virtual devices of the same type with the
same redundancy level in each device.</p>
         </div>
      </td>
   </tr>

   <tr class="PageControls" valign="top">
      <td></td>
      <td>
         <table width="100%">
      	   <tr>
      	     <td>
                 <a href="gcfog.html">Previous</a>
             </td>
             <td align="right">
                 <a href="gaypw.html">Next</a>
             </td>
           </tr>
         </table>
      </td>
   </tr>
</tbody>
</table>


</body>
</html>

