<chapter id="tasks-basics-2"><title>Maintaining Solaris Volume Manager (Tasks)</title><highlights><para>This chapter provides information about performing general storage administration
maintenance tasks with Solaris Volume Manager. </para><para>This is a list of the information in this chapter:</para><itemizedlist><listitem><para><olink targetptr="tasks-basics-33" remap="internal">Solaris Volume Manager
Maintenance (Task Map)</olink></para>
</listitem><listitem><para><olink targetptr="tasks-basics-28" remap="internal">Viewing the Solaris Volume
Manager Configuration</olink></para>
</listitem><listitem><para><olink targetptr="tasks-basics-5" remap="internal">Renaming Volumes</olink></para>
</listitem><listitem><para><olink targetptr="tasks-basics-6" remap="internal">Working With Configuration
Files</olink></para>
</listitem><listitem><para><olink targetptr="troubleshoottasks-13" remap="internal">Changing Solaris Volume
Manager Default Values</olink></para>
</listitem><listitem><para><olink targetptr="tasks-metadevices-41" remap="internal">Expanding a File System
Using the growfs Command</olink></para>
</listitem><listitem><para><olink targetptr="replace-enable-1" remap="internal">Overview of Replacing
and Enabling Components in RAID-1 and RAID-5 Volumes</olink></para>
</listitem>
</itemizedlist>
</highlights><sect1 id="tasks-basics-33"><title>Solaris Volume Manager Maintenance (Task Map)</title><para>The following task map identifies the procedures that are needed to
maintain Solaris Volume Manager.</para><informaltable frame="all"><tgroup cols="3" colsep="1" rowsep="1"><colspec colname="colspec0" colwidth="110.00*"/><colspec colname="colspec1" colwidth="167.00*"/><colspec colname="colspec2" colwidth="119.00*"/><thead><row><entry><para>Task</para>
</entry><entry><para>Description</para>
</entry><entry><para>For Instructions</para>
</entry>
</row>
</thead><tbody><row><entry><para>View the Solaris Volume Manager configuration</para>
</entry><entry><para>Use the Solaris Volume Manager GUI or the <command>metastat</command> command
to view the system configuration. </para>
</entry><entry><para><olink targetptr="tasks-basics-29" remap="internal">How to View the Solaris Volume Manager
Volume Configuration</olink></para>
</entry>
</row><row><entry><para>Rename a volume</para>
</entry><entry><para>Use the Solaris Volume Manager GUI or the <command>metarename</command> command
to rename a volume. </para>
</entry><entry><para><olink targetptr="tasks-metadevices-9" remap="internal">How to Rename a Volume</olink></para>
</entry>
</row><row><entry><para>Create configuration files</para>
</entry><entry><para>Use the <command>metastat -p</command> command and the <command>metadb</command> command
to create configuration files.</para>
</entry><entry><para><olink targetptr="tasks-basics-1" remap="internal">How to Create Configuration Files</olink></para>
</entry>
</row><row><entry><para>Initialize Solaris Volume Manager from configuration files</para>
</entry><entry><para>Use the <command>metainit</command> command to initialize Solaris Volume Manager from
configuration files.</para>
</entry><entry><para><olink targetptr="troubleshoottasks-23827" remap="internal">How to Initialize Solaris
Volume Manager From a Configuration File</olink></para>
</entry>
</row><row><entry><para>Expand a file system</para>
</entry><entry><para>Use the <command>growfs</command> command to expand a file system.</para>
</entry><entry><para><olink targetptr="tasks-metadevices-7" remap="internal">How to Expand a File System</olink></para>
</entry>
</row><row><entry><para>Enable components</para>
</entry><entry><para>Use the Solaris Volume Manager GUI or the <command>metareplace</command> command
to enable components. </para>
</entry><entry><para><olink targetptr="replace-enable-2" remap="internal">Enabling a Component</olink></para>
</entry>
</row><row><entry><para>Replace components</para>
</entry><entry><para>Use the Solaris Volume Manager GUI or the <command>metareplace</command> command
to replace components. </para>
</entry><entry><para><olink targetptr="replace-enable-3" remap="internal">Replacing a Component With Another
Available Component</olink></para>
</entry>
</row>
</tbody>
</tgroup>
</informaltable>
</sect1><sect1 id="tasks-basics-28"><title>Viewing the Solaris Volume Manager Configuration</title><tip><para>The <command>metastat</command> command does not sort output. Pipe
the output of the <command>metastat -p</command> command to the <command>sort</command> or <command>grep</command> commands for a more manageable listing of your configuration.</para>
</tip><task id="tasks-basics-29"><title>How to View the Solaris Volume Manager Volume Configuration</title><procedure remap="single-step"><step id="tasks-basics-step-31"><para>To view the volume configuration, use
one of the following methods:</para><itemizedlist><listitem><para>From the Enhanced Storage tool within the Solaris Management Console, open the Volumes node. For more information,
see the online help.</para>
</listitem><listitem><para>Use the following form of the <command>metastat</command> command:</para><screen># <userinput>metastat -p -i <replaceable>component-name</replaceable></userinput></screen><variablelist><varlistentry><term><option>p</option></term><listitem><para>Specifies to show output in a condensed summary. This output
is suitable for use in creating the <filename>md.tab</filename> file.</para>
</listitem>
</varlistentry><varlistentry><term><option>i</option></term><listitem><para>Specifies to verify that RAID-1 (mirror) volumes, RAID-5 volumes,
and hot spares can be accessed.</para>
</listitem>
</varlistentry><varlistentry><term><replaceable>component-name</replaceable></term><listitem><para>Specifies the name of the volume to view. If no volume name
is specified, a complete list of components is displayed.</para>
</listitem>
</varlistentry>
</variablelist>
</listitem>
</itemizedlist>
</step>
</procedure><example id="egjvs"><title>Viewing the Solaris Volume Manager Volume Configuration</title><para>The following example illustrates output from the <command>metastat</command> command.</para><screen width="100"># <userinput>metastat</userinput>
d50: RAID
    State: Okay         
    Interlace: 32 blocks
    Size: 20985804 blocks
Original device:
    Size: 20987680 blocks
        Device              Start Block  Dbase State        Reloc  Hot Spare
        c1t4d0s5                 330     No    Okay         Yes    
        c1t5d0s5                 330     No    Okay         Yes    
        c2t4d0s5                 330     No    Okay         Yes    
        c2t5d0s5                 330     No    Okay         Yes    
        c1t1d0s5                 330     No    Okay         Yes    
        c2t1d0s5                 330     No    Okay         Yes    

d1: Concat/Stripe
    Size: 4197879 blocks
    Stripe 0:
        Device              Start Block  Dbase  Reloc
        c1t2d0s3                   0     No     Yes

d2: Concat/Stripe
    Size: 4197879 blocks
    Stripe 0:
        Device              Start Block  Dbase  Reloc
        c2t2d0s3                   0     No     Yes


d80: Soft Partition
    Device: d70
    State: Okay
    Size: 2097152 blocks
        Extent              Start Block              Block count
             0                        1                  2097152

d81: Soft Partition
    Device: d70
    State: Okay
    Size: 2097152 blocks
        Extent              Start Block              Block count
             0                  2097154                  2097152

d70: Mirror
    Submirror 0: d71
      State: Okay         
    Submirror 1: d72
      State: Okay         
    Pass: 1
    Read option: roundrobin (default)
    Write option: parallel (default)
    Size: 12593637 blocks

d71: Submirror of d70
    State: Okay         
    Size: 12593637 blocks
    Stripe 0:
        Device              Start Block  Dbase State        Reloc  Hot Spare
        c1t3d0s3                   0     No    Okay         Yes    
    Stripe 1:
        Device              Start Block  Dbase State        Reloc  Hot Spare
        c1t3d0s4                   0     No    Okay         Yes    
    Stripe 2:
        Device              Start Block  Dbase State        Reloc  Hot Spare
        c1t3d0s5                   0     No    Okay         Yes    


d72: Submirror of d70
    State: Okay         
    Size: 12593637 blocks
    Stripe 0:
        Device              Start Block  Dbase State        Reloc  Hot Spare
        c2t3d0s3                   0     No    Okay         Yes    
    Stripe 1:
        Device              Start Block  Dbase State        Reloc  Hot Spare
        c2t3d0s4                   0     No    Okay         Yes    
    Stripe 2:
        Device              Start Block  Dbase State        Reloc  Hot Spare
        c2t3d0s5                   0     No    Okay         Yes    

hsp010: is empty

hsp014: 2 hot spares
        Device              Status      Length          Reloc
        c1t2d0s1            Available    617652 blocks  Yes
        c2t2d0s1            Available    617652 blocks  Yes

hsp050: 2 hot spares
        Device              Status      Length          Reloc
        c1t2d0s5            Available    4197879 blocks Yes
        c2t2d0s5            Available    4197879 blocks Yes

hsp070: 2 hot spares
        Device              Status      Length          Reloc
        c1t2d0s4            Available    4197879 blocks Yes
        c2t2d0s4            Available    4197879 blocks Yes

Device Relocation Information:
Device              Reloc       Device ID
c1t2d0              Yes         id1,sd@SSEAGATE_ST39204LCSUN9.0G3BV0N1S200002103AF29
c2t2d0              Yes         id1,sd@SSEAGATE_ST39204LCSUN9.0G3BV0P64Z00002105Q6J7
c1t1d0              Yes         id1,sd@SSEAGATE_ST39204LCSUN9.0G3BV0N1EM00002104NP2J
c2t1d0              Yes         id1,sd@SSEAGATE_ST39204LCSUN9.0G3BV0N93J000071040L3S
c0t0d0              Yes         id1,dad@s53554e575f4154415f5f53543339313430412525415933
 </screen>
</example><example id="eyprm"><title>Viewing a Multi-Terabyte Solaris Volume Manager Volume</title><para>The following example illustrates output from the <command>metastat</command> command
for a multi-terabyte storage volume (11 Tbytes).</para><screen width="100"># <userinput>metastat d0</userinput>
 d0: Concat/Stripe
    Size: 25074708480 blocks (11 TB)
    Stripe 0: (interlace: 32 blocks)
        Device      Start Block  Dbase  Reloc
        c27t8d3s0          0     No     Yes
        c4t7d0s0       12288     No     Yes
    Stripe 1: (interlace: 32 blocks)
        Device      Start Block  Dbase  Reloc
        c13t2d1s0      16384     No     Yes
        c13t4d1s0      16384     No     Yes
        c13t6d1s0      16384     No     Yes
        c13t8d1s0      16384     No     Yes
        c16t3d0s0      16384     No     Yes
        c16t5d0s0      16384     No     Yes
        c16t7d0s0      16384     No     Yes
        c20t4d1s0      16384     No     Yes
        c20t6d1s0      16384     No     Yes
        c20t8d1s0      16384     No     Yes
        c9t1d0s0       16384     No     Yes
        c9t3d0s0       16384     No     Yes
        c9t5d0s0       16384     No     Yes
        c9t7d0s0       16384     No     Yes
    Stripe 2: (interlace: 32 blocks)
        Device      Start Block  Dbase  Reloc
        c27t8d2s0      16384     No     Yes
        c4t7d1s0       16384     No     Yes
    Stripe 3: (interlace: 32 blocks)
        Device      Start Block  Dbase  Reloc
        c10t7d0s0      32768     No     Yes
        c11t5d0s0      32768     No     Yes
        c12t2d1s0      32768     No     Yes
        c14t1d0s0      32768     No     Yes
        c15t8d1s0      32768     No     Yes
        c17t3d0s0      32768     No     Yes
        c18t6d1s0      32768     No     Yes
        c19t4d1s0      32768     No     Yes
        c1t5d0s0       32768     No     Yes
        c2t6d1s0       32768     No     Yes
        c3t4d1s0       32768     No     Yes
        c5t2d1s0       32768     No     Yes
        c6t1d0s0       32768     No     Yes
        c8t3d0s0       32768     No     Yes</screen>
</example>
</task><sect2 id="tasks-basics-71"><title>Where To Go From Here</title><para>For more information, see the <olink targetdoc="refman1m" targetptr="metastat-1m" remap="external"><citerefentry><refentrytitle>metastat</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink> man page. </para>
</sect2>
</sect1><sect1 id="tasks-basics-5"><title>Renaming Volumes</title><sect2 id="maintaintasksnew-34278"><title>Background Information for Renaming
Volumes</title><para>Solaris Volume Manager enables you to rename most types of volumes at
any time, subject to some constraints. You can use either the Enhanced Storage tool within the Solaris Management Console or
the command line (the <olink targetdoc="refman1m" targetptr="metarename-1m" remap="external"><citerefentry><refentrytitle>metarename</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink> command) to rename volumes. </para><para>Renaming volumes or switching volume names is an administrative convenience
for the management of volume names. For example, you could arrange all file
system mount points in a desired numeric range. You might rename volumes to
maintain a naming scheme for your logical volumes or to allow a transactional
volume to use the same name as the name of the underlying volume.</para><note><para>Transactional volumes are no longer valid in Solaris Volume Manager. You
can rename transactional volumes to replace them.</para>
</note><para>Before you rename a volume, make sure that it is not currently in use.
For a file system, make sure that it is not mounted or being used as <filename>swap</filename>. Other applications that use the raw device, such as a database,
should have their own way of stopping access to the data.</para><para>Specific considerations for renaming volumes include the following:</para><itemizedlist><listitem><para>You can rename any volume except the following:</para><itemizedlist><listitem><para>Soft partitions</para>
</listitem><listitem><para>Volumes on which soft partitions are directly built</para>
</listitem><listitem><para>Volumes that are being used as log devices</para>
</listitem><listitem><para>Hot spare pools </para>
</listitem>
</itemizedlist>
</listitem><listitem><para>You can rename volumes within a disk set. However, you cannot
rename volumes to move them from one disk set to another disk set.</para>
</listitem>
</itemizedlist>
</sect2><sect2 id="basics-23"><title>Exchanging Volume Names</title><para>Using the <command>metarename</command> command with the <command><option>x</option></command> option exchanges the names of volumes that have a parent-child
relationship. For more information, see <olink targetptr="tasks-metadevices-9" remap="internal">How
to Rename a Volume</olink> and the <olink targetdoc="refman1m" targetptr="metarename-1m" remap="external"><citerefentry><refentrytitle>metarename</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink> man page. The name of an
existing volume is exchanged with one of its subcomponents. For example, this
type of exchange can occur between a mirror and one of its submirrors. The <command>metarename <option>x</option></command> command can make it easier to mirror or unmirror an existing
volume.</para><note><para>You must use the command line to exchange volume names. This functionality
is currently unavailable in the Solaris Volume Manager GUI. However, you can rename
a volume with either the command line or the GUI.</para>
</note><para>Consider the following guidelines when you want to rename a volume:</para><itemizedlist><listitem><para>You cannot rename a volume that is currently in use. This
restriction includes volumes that are used as mounted file systems, as <filename>swap</filename>, or as active storage for applications or databases. Thus,
before you use the <command>metarename</command> command, stop all access
to the volume that is being renamed. For example, unmount a mounted file system. </para>
</listitem><listitem><para>You cannot exchange volumes in a failed state.</para>
</listitem><listitem><para>You cannot exchange volumes that are using a hot spare replacement.</para>
</listitem><listitem><para>An exchange can only take place between volumes with a direct
parent-child relationship. </para>
</listitem><listitem><para>You cannot exchange (or rename) a log device. The workaround
is to detach the log device and attach another
log device of the desired name.</para>
</listitem><listitem><para>Only volumes can be exchanged. You cannot exchange slices
or hot spares.  </para>
</listitem>
</itemizedlist>
</sect2><task id="tasks-metadevices-9"><title>How to Rename a Volume</title><taskprerequisites><para>Check the volume name requirements (<olink targetptr="basics-34" remap="internal">Volume
Names</olink>), and <olink targetptr="maintaintasksnew-34278" remap="internal">Background Information
for Renaming Volumes</olink>.</para>
</taskprerequisites><procedure><step id="tasks-basics-step-12"><para>Unmount the file system that uses the
volume.</para><screen># <userinput>umount /<replaceable>filesystem</replaceable></userinput></screen>
</step><step id="tasks-basics-step-13"><para>To rename the volume, use one of the
following methods:</para><itemizedlist><listitem><para>From the Enhanced Storage tool within the Solaris Management Console, open the Volumes. Select the volume you
want to rename. Click the right mouse on the icon. Choose the Properties option.
Then, follow the onscreen instructions. For more information, see the online
help.</para>
</listitem><listitem><para>Use the following form of the <command>metarename</command> command:</para><screen># <userinput>metarename <replaceable>old-volume-name</replaceable> <replaceable>new-volume-name</replaceable></userinput></screen><variablelist><varlistentry><term><replaceable>old-volume-name</replaceable></term><listitem><para>Specifies the name of the existing volume.</para>
</listitem>
</varlistentry><varlistentry><term><replaceable>new-volume-name</replaceable></term><listitem><para>Specifies  the new name for the existing volume.</para>
</listitem>
</varlistentry>
</variablelist><para>See the <olink targetdoc="refman1m" targetptr="metarename-1m" remap="external"><citerefentry><refentrytitle>metarename</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink> man page for more information.</para>
</listitem>
</itemizedlist>
</step><step id="tasks-basics-step-14"><para>Edit the <filename>/etc/vfstab</filename> file
to refer to the new volume name, if necessary.</para>
</step><step id="tasks-basics-step-15"><para>Remount the file system.</para><screen># <userinput>mount /<replaceable>filesystem</replaceable></userinput></screen>
</step>
</procedure><example id="egjvq"><title>Renaming a Volume Used for a File System</title><para>In the following example, the volume, <filename>d10</filename>, is renamed
to <filename>d100</filename>.</para><screen># <userinput>umount /home</userinput>
# <userinput>metarename d10 d100</userinput>
d10: has been renamed to d100
<lineannotation>(Edit the /etc/vfstab file so that the file system  references the new volume)</lineannotation>
# <userinput>mount /home</userinput></screen><para>Because <filename>d10</filename> contains a mounted file system,
the file system must be unmounted before the volume can be renamed. If the
volume is used for a file system with an entry in the <filename>/etc/vfstab</filename> file,
the entry must be changed to reference the new volume name.</para><para>For example, if the <filename>/etc/vfstab file</filename> contains the
following entry for the file system:</para><screen>/dev/md/dsk/d10 /dev/md/rdsk/d10 /docs home 2 yes -</screen><para>Change the entry to read as follows:</para><screen>/dev/md/dsk/d100 /dev/md/rdsk/d100 /docs home 2 yes -</screen><para>Then, remount the file system.</para><para>If you have an existing mirror or transactional volume, you can use
the <command>metarename <option>x</option></command> command to remove the
mirror or transactional volume and keep data on the underlying volume. For
a transactional volume, as long as the master device is a volume ( either
a RAID-0, RAID-1, or RAID-5 volume), you can keep data on that volume.</para>
</example>
</task>
</sect1><sect1 id="tasks-basics-6"><title>Working With Configuration Files</title><para>Solaris Volume Manager configuration files contain basic Solaris Volume Manager information,
as well as most of the data that is necessary to reconstruct a configuration.
The following procedures illustrate how to work with these files. </para><task id="tasks-basics-1"><title>How to Create Configuration Files</title><procedure remap="single-step"><step id="tasks-basics-step-17"><para>Once you have defined all appropriate
parameters for the Solaris Volume Manager environment, use the <command>metastat <option>p</option></command> command to create the <filename>/etc/lvm/md.tab</filename> file. </para><screen># <userinput>metastat -p > /etc/lvm/md.tab</userinput></screen><para>This file contains all parameters for use by the <command>metainit</command> command
and <command>metahs</command> command. Use this file if you need to set up
several similar environments or if you need to recreate the configuration
after a system failure.</para><para>For more information about the <filename>md.tab</filename> file, see <olink targetptr="basics-28" remap="internal">Overview of the md.tab
File</olink> and the <olink targetdoc="refman4" targetptr="md.tab-4" remap="external"><citerefentry><refentrytitle>md.tab</refentrytitle><manvolnum>4</manvolnum></citerefentry></olink> man
page.</para>
</step>
</procedure>
</task><task id="troubleshoottasks-23827"><title>How to Initialize Solaris Volume Manager From
a Configuration File</title><tasksummary><caution><para>Use this procedure in the following circumstances:</para><itemizedlist><listitem><para>If you have experienced a complete loss of your Solaris Volume Manager configuration</para>
</listitem><listitem><para>If you have no configuration yet, and you want to create a
configuration from a saved configuration file</para>
</listitem>
</itemizedlist>
</caution><para>On occasion, your system loses the information maintained in the state
database. For example, this loss might occur if the system was rebooted after
all of the state database replicas were deleted. As long as no volumes were
created after the state database was lost, you can use the <filename>md.cf</filename> or <filename>md.tab</filename> files to recover your Solaris Volume Manager configuration.</para><note><para>The <filename>md.cf</filename> file does not maintain information
on active hot spares. Thus, if hot spares were in use when the Solaris Volume Manager configuration
was lost, those volumes that were using active hot spares are likely corrupted.</para>
</note><para>For more information about these files, see the <olink targetdoc="refman4" targetptr="md.cf-4" remap="external"><citerefentry><refentrytitle>md.cf</refentrytitle><manvolnum>4</manvolnum></citerefentry></olink> and the <olink targetdoc="refman4" targetptr="md.tab-4" remap="external"><citerefentry><refentrytitle>md.tab</refentrytitle><manvolnum>4</manvolnum></citerefentry></olink> man pages.</para>
</tasksummary><procedure><step id="troubleshoottasks-step-5"><para>Create state database replicas.</para><para>See <olink targetptr="tasks-state-db-replicas-9" remap="internal">Creating State Database
Replicas</olink> for more information.</para>
</step><step id="troubleshoottasks-step-6"><para>Create or update the <filename>/etc/lvm/md.tab</filename> file.</para><itemizedlist><listitem><para>If you are attempting to recover the last known Solaris Volume Manager configuration,
copy the <filename>md.cf</filename> file into the <filename>/etc/lvm/md.tab</filename> file.</para>
</listitem><listitem><para>If you are creating a new Solaris Volume Manager configuration based
on a copy of the <filename>md.tab</filename> file that have you preserved,
copy the preserved file into the <filename>/etc/lvm/md.tab</filename> file.</para>
</listitem>
</itemizedlist>
</step><step id="troubleshoottasks-step-8"><para>Edit the &ldquo;new&rdquo; <filename>/etc/lvm/md.tab</filename> file and do the following:</para><itemizedlist><listitem><para>If you are creating a new configuration or recovering a configuration
after a crash, configure the mirrors as one-way mirrors. For example:</para><screen>d80 -m d81 1
d81 1 1 c1t6d0s3</screen><para>If the submirrors of a mirror are not the same size, be sure to use
the smallest submirror for this one-way mirror. Otherwise, data could be lost.</para>
</listitem><listitem><para>If you are recovering an existing configuration and Solaris Volume Manager was
cleanly stopped, leave the mirror configuration as multi-way mirrors. For
example:</para><screen>d70 -m d71 d72 1
d71 1 1 c1t6d0s2
d72 1 1 c1t5d0s0</screen>
</listitem><listitem><para>Specify RAID-5 volumes with the <option>k</option> option,
to prevent reinitialization of the device. For example:</para><screen>d45 -r c1t3d0s5 c1t3d0s3 c1t3d0s4 -k -i 32b</screen><para>See the <olink targetdoc="refman1m" targetptr="metainit-1m" remap="external"><citerefentry><refentrytitle>metainit</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink> man
page for more information.</para>
</listitem>
</itemizedlist>
</step><step id="troubleshoottasks-step-9"><para>Check the syntax of the <filename>/etc/lvm/md.tab</filename> file
entries without committing changes by using one of the following forms of
the <command>metainit </command>command: </para><screen># <userinput>metainit -n <replaceable>md.tab-entry</replaceable></userinput></screen><screen># <userinput>metainit -n -a</userinput></screen><para>The <command>metainit</command> command does not maintain a hypothetical
state of the devices that might have been created while running with the <option>n</option>, so creating volumes that rely on other, nonexistent volumes will
result in errors with the <option>n</option> even though the command may succeed
without the <option>n</option> option.</para><variablelist><varlistentry><term><option>n</option></term><listitem><para>Specifies not to actually create the devices. Use this option
to verify that the results are as you expected.</para>
</listitem>
</varlistentry><varlistentry><term><replaceable>md.tab-entry</replaceable></term><listitem><para>Specifies the name of the component to initialize.</para>
</listitem>
</varlistentry><varlistentry><term><option>a</option></term><listitem><para>Specifies to check all components.</para>
</listitem>
</varlistentry>
</variablelist>
</step><step id="troubleshoottasks-step-10"><para>If no problems were apparent from
the previous step, recreate the volumes and hot spare pools from the <filename>md.tab</filename> file:</para><screen># <userinput>metainit -a</userinput></screen><variablelist><varlistentry><term><option>a</option></term><listitem><para>Specifies to activate the entries in the <filename>/etc/lvm/md.tab
file</filename>.</para>
</listitem>
</varlistentry>
</variablelist>
</step><step id="troubleshoottasks-step-11"><para>As needed, make the one-way mirrors into multi-way mirrors by
using the <command>metattach</command> command.</para><screen># <userinput>mettach <replaceable>mirror</replaceable> <replaceable>submirror</replaceable></userinput></screen>
</step><step id="troubleshoottasks-step-12"><para>Validate the data on the volumes
to confirm that the configuration has been reconstructed accurately.</para><screen># <userinput>metastat</userinput></screen>
</step>
</procedure>
</task>
</sect1><sect1 id="troubleshoottasks-13"><title>Changing Solaris Volume Manager Default Values</title><para>With the Solaris 10 release, Solaris Volume Manager has been enhanced to configure
volumes dynamically. You no longer need to edit the <literal>nmd</literal> and
the <literal>md_nsets</literal> parameters in the <filename>/kernel/drv/md.conf</filename> file.
New volumes are dynamically created, as needed.</para><para>The maximum Solaris Volume Manager configuration values remain unchanged:</para><itemizedlist><listitem><para>The maximum number of volumes that is supported is 8192.</para>
</listitem><listitem><para>The maximum number of disk sets supported is 32.</para>
</listitem>
</itemizedlist>
</sect1><sect1 id="tasks-metadevices-41"><title>Expanding a File System Using the <command>growfs</command> Command</title><para>After a volume that contains a UFS file system is expanded (meaning
that more space is added), you also need to expand the file system in order
to recognize the added space. You must manually expand the file system with
the <command>growfs</command> command. The <command>growfs</command> command
expands the file system, even while the file system is mounted. However, write
access to the file system is not possible while the <command>growfs</command> command
is running. </para><para>An application, such as a database, that uses the raw device must have
its own method to incorporate the added space. Solaris Volume Manager does not provide
this capability. </para><para>The <command>growfs</command> command &ldquo;write-locks&rdquo; a mounted
file system as it expands the file system. The length of time the file system
is write-locked can be shortened by expanding the file system in stages. For
instance, to expand a 1-Gbyte file system to 2 Gbytes, the file system can
be grown in 16 Mbyte stages by using the <option>s</option> option. This option
specifies the total size of the new file system at each stage. </para><para>During the expansion, the file system is not available for write access
because of the write-lock feature. Write accesses are transparently suspended
and are restarted when the <command>growfs</command> command unlocks the file
system. Read accesses are not affected. However, access times are not kept
while the lock is in effect. </para><sect2 id="basics-10"><title>Background Information for Expanding Slices and
Volumes</title><note><para>Solaris Volume Manager volumes can be expanded. However, volumes cannot
be reduced in size.</para>
</note><itemizedlist><listitem><para>A volume can be expanded whether it is used for a file system,
application, or database. You can expand RAID-0 (stripe and concatenation)
volumes, RAID-1 (mirror) volumes, and RAID-5 volumes and soft partitions.</para>
</listitem><listitem><para>You can concatenate a volume that contains an existing file
system while the file system is in use. As long as the file system is a UFS
file system, the file system can be expanded (with the <command>growfs</command> command)
to fill the larger space. You can expand the file system without interrupting
read access to the data.</para>
</listitem><listitem><para>Once a file system is expanded, it cannot be reduced in size,
due to constraints in the UFS file system.</para>
</listitem><listitem><para>Applications and databases that use the raw device must have
their own method to expand the added space so that they can recognize it. Solaris Volume Manager does
not provide this capability.</para>
</listitem><listitem><para>When a component is added to a RAID-5 volume, it becomes a
concatenation to the volume. The new component does not contain parity information.
However, data on the new component is protected by the overall parity calculation
that takes place for the volume.</para>
</listitem><listitem><para>You can expand a log device by adding additional components.
You do not need to run the <command>growfs</command> command, as Solaris Volume Manager automatically
recognizes the additional space on reboot. </para>
</listitem><listitem><para>Soft partitions can be expanded by adding space from the underlying
volume or slice. All other volumes can be expanded by adding slices.</para>
</listitem>
</itemizedlist>
</sect2><task id="tasks-metadevices-7"><title>How to Expand a File System</title><taskprerequisites><para>Check <olink targetptr="addtasks-20933" remap="internal">Prerequisites for Creating Solaris
Volume Manager Components</olink>.</para>
</taskprerequisites><procedure><step><para>Review the disk space associated with a file system.</para><screen># <userinput>df -hk</userinput></screen><para>See the <olink targetdoc="refman1m" targetptr="df-1m" remap="external"><citerefentry><refentrytitle>df</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink> man
page for more information.</para>
</step><step id="tasks-metadevices-step-70"><para>Expand a UFS file system on a logical
volume.</para><screen># <userinput>growfs -M <replaceable>/mount-point</replaceable> /dev/md/rdsk/<replaceable>volume-name</replaceable></userinput></screen><variablelist><varlistentry><term><option>M</option> <replaceable>/mount-point</replaceable></term><listitem><para>Specifies the mount point for the file system to be expanded.</para>
</listitem>
</varlistentry><varlistentry><term><filename>/dev/md/rdsk/<replaceable>volume-name</replaceable></filename></term><listitem><para>Specifies the name of the volume on which you want to expand.</para>
</listitem>
</varlistentry>
</variablelist><para>See the following example and the <olink targetdoc="refman1m" targetptr="growfs-1m" remap="external"><citerefentry><refentrytitle>growfs</refentrytitle><manvolnum>1M</manvolnum></citerefentry></olink> man page for more information.</para>
</step>
</procedure><example id="egjvr"><title>Expanding a File System</title><para>In the following example, a new slice is added to a volume, <filename>d10</filename>,
which contains the mounted file system, <filename>/home2</filename>. The <command>growfs</command> command specifies the mount point with the <option>M</option> option
to be <filename>/home2</filename>, which is expanded onto the raw volume <filename>/dev/md/rdsk/d10</filename>. The file system will span the entire volume when
the <command>growfs</command> command is complete. You can use the <command>df</command> <option>hk</option> command before and after expanding the file system to verify the
total disk capacity.</para><screen width="100"># <userinput>df -hk</userinput>
Filesystem            kbytes    used   avail capacity  Mounted on
...
/dev/md/dsk/d10        69047   65426       0   100%    /home2
...
# <userinput>growfs -M /home2 /dev/md/rdsk/d10</userinput>
/dev/md/rdsk/d10:       295200 sectors in 240 cylinders of 15 tracks, 82 sectors
        144.1MB in 15 cyl groups (16 c/g, 9.61MB/g, 4608 i/g)
super-block backups (for fsck -F ufs -o b=#) at:
 32, 19808, 39584, 59360, 79136, 98912, 118688, 138464, 158240, 178016, 197792,
 217568, 237344, 257120, 276896,
# <userinput>df -hk</userinput>
Filesystem            kbytes    used   avail capacity  Mounted on
...
/dev/md/dsk/d10       138703   65426   59407    53%    /home2
...</screen><para>For mirror  volumes, always
run the <command>growfs</command> command on the top-level volume. Do not
run the command on a submirror or master device, even though space is added
to the submirror or master device.</para>
</example>
</task>
</sect1><sect1 id="replace-enable-1"><title>Overview of Replacing and Enabling Components
in RAID-1 and RAID-5 Volumes</title><para>Solaris Volume Manager can <emphasis>replace</emphasis> and <emphasis>enable</emphasis> components
within RAID-1 (mirror) and RAID-5 volumes. </para><para>In Solaris Volume Manager terminology, <emphasis>replacing</emphasis> a component
is a way to substitute an available component on the system for a selected
component in a submirror or RAID-5 volume. You can think of this process as
logical replacement, as opposed to physically replacing the component. For
more information see <olink targetptr="replace-enable-3" remap="internal">Replacing a Component
With Another Available Component</olink>.</para><para><emphasis>Enabling</emphasis> a component means to &ldquo;activate&rdquo;
or substitute a component with itself (that is, the component name is the
same). For more information, see <olink targetptr="replace-enable-2" remap="internal">Enabling
a Component</olink>.</para><note><para>When recovering from disk errors, scan <filename>/var/adm/messages</filename> to
see what kind of errors occurred. If the errors are transitory and the disks
themselves do not have problems, try enabling the failed components. You can
also use the <command>format</command> command to test a disk. </para>
</note><sect2 id="replace-enable-2"><title>Enabling a Component</title><para>You can enable a component when any of the following conditions exist:</para><itemizedlist><listitem><para>Solaris Volume Manager cannot access the physical drive. This problem
might occur, for example, due to a power loss, or a loose drive cable. In
this case, Solaris Volume Manager puts the components in the &ldquo;Maintenance&rdquo;
state. You need to make sure that the drive is accessible (restore power,
reattach cables, and so on), and then enable the components in the volumes.</para>
</listitem><listitem><para>You suspect that a physical drive is having transitory problems
that are not disk-related. You might be able to fix a component in the &ldquo;Maintenance&rdquo;
state by simply enabling it. If enabling the component does not fix the problem,
then you need to do one of the following:</para><itemizedlist><listitem><para>Physically replace the disk drive and enable the component</para>
</listitem><listitem><para>Replace the component with another available component on
the system</para>
</listitem>
</itemizedlist><para>When you physically replace a disk, be sure to partition the disk like
the replaced disk to ensure adequate space on each used component.</para>
</listitem>
</itemizedlist><note><para>Always check for state database replicas and hot spares on the
disk that is being replaced. Any state database replica in an erred state
should be deleted before you replace the disk. Then, after you enable the
component, recreate the state database replicas using the same size. You should
treat hot spares in the same manner.</para>
</note>
</sect2><sect2 id="replace-enable-3"><title>Replacing a Component With Another Available
Component</title><para>You use the <command>metareplace</command> command when you replace
or swap an existing component with a different component that is available
and not in use on the system.</para><para>You can use this command when any of the following conditions exist:</para><itemizedlist><listitem><para>A disk drive has problems, and you do not have a replacement
drive. However, you do have available components elsewhere on the system. </para><para>You might want to use this strategy when a replacement is absolutely
necessary, but you do not want to shut down the system.</para>
</listitem><listitem><para>You see soft errors on the physical disks. </para><para>Physical
disks might report soft errors even though Solaris Volume Manager shows the mirror/submirror
or RAID-5 volume in the &ldquo;Okay&rdquo; state. Replacing the component
in question with another available component enables you to perform preventative
maintenance and potentially prevent hard errors from occurring.</para>
</listitem><listitem><para>You want to do performance tuning. </para><para>One way that
you can evaluate components is by using the performance monitoring feature
available from the Enhanced Storage tool within the Solaris Management Console. For example, you might see that a particular
component in a RAID-5 volume is experiencing a high load average, even though
it is in the &ldquo;Okay&rdquo; state. To balance the load on the volume,
you can replace that component with a component from a disk that is less utilized.
You can perform this type of replacement online without interrupting service
to the volume.</para>
</listitem>
</itemizedlist>
</sect2><sect2 id="replace-enable-4"><title>Maintenance and Last Erred States</title><para>When a component in a RAID-1 or RAID-5 volume experiences errors, Solaris Volume Manager puts
the component in the &ldquo;Maintenance&rdquo; state. No further reads or
writes are performed to a component in the &ldquo;Maintenance&rdquo; state.</para><para>Sometimes a component goes into a &ldquo;Last Erred&rdquo; state. For
a RAID-1 volume, this usually occurs with a one-sided mirror. The volume experiences
errors. However, there are no redundant components to read from. For a RAID-5
volume this occurs after one component goes into &ldquo;Maintenance&rdquo;
state, and another component fails. The second component to fail goes into
the &ldquo;Last Erred&rdquo; state.</para><para>When either a RAID-1 volume or a RAID-5 volume has a component in the &ldquo;Last
Erred&rdquo; state, I/O is still attempted to the component marked &ldquo;Last
Erred.&rdquo; This I/O attempt occurs because a &ldquo;Last Erred&rdquo; component
contains the last good copy of data from Solaris Volume Manager's point of view.
With a component in the &ldquo;Last Erred&rdquo; state, the volume behaves
like a normal device (disk) and returns I/O errors to an application. Usually,
at this point, some data has been lost. </para><para>The subsequent errors on other components in the same volume are handled
differently, depending on the type of volume. </para><variablelist><varlistentry><term>RAID-1 Volume</term><listitem><para>A RAID-1 volume might be able to tolerate many components
in the &ldquo;Maintenance&rdquo; state and still be read from and written
to. If components are in the &ldquo;Maintenance&rdquo; state, no data has
been lost. You can safely replace or enable the components in any order. If
a component is in the &ldquo;Last Erred&rdquo; state, you cannot replace it
until you first replace the components in the &ldquo;Maintenance&rdquo; state.
Replacing or enabling a component in the &ldquo;Last Erred&rdquo; state usually
means that some data has been lost. Be sure to validate the data on the mirror
after you repair it.</para>
</listitem>
</varlistentry><varlistentry><term>RAID-5 Volume</term><listitem><para>A RAID-5 volume can tolerate a single component in the &ldquo;Maintenance&rdquo;
state. You can safely replace a single component in the &ldquo;Maintenance&rdquo;
state without losing data. If an error on another component occurs, it is
put into the &ldquo;Last Erred&rdquo; state. At this point, the RAID-5 volume
is a read-only device. You need to perform some type of error recovery so
that the state of the RAID-5 volume is stable and the possibility of data
loss is reduced. If a RAID-5 volume reaches a &ldquo;Last Erred&rdquo; state,
there is a good chance it has lost data. Be sure to validate the data on the
RAID-5 volume after you repair it.</para>
</listitem>
</varlistentry>
</variablelist><para>Always replace components in the &ldquo;Maintenance&rdquo; state first,
followed by those in the &ldquo;Last Erred&rdquo; state. After a component
is replaced and resynchronized, use the <command>metastat</command> command
to verify its state. Then, validate the data.</para>
</sect2><sect2 id="replace-enable-5"><title>Background Information for Replacing and
Enabling Components in RAID-1 and RAID-5 Volumes</title><para>When you replace components in a RAID-1 volume or a RAID-5 volume,
follow these guidelines: </para><itemizedlist><listitem><para>Always replace components in the &ldquo;Maintenance&rdquo;
state first, followed by those components in the &ldquo;Last Erred&rdquo;
state.</para>
</listitem><listitem><para>After a component is replaced and resynchronized, use the <command>metastat</command> command to verify the state of the volume. Then, validate
the data. Replacing or enabling a component in the &ldquo;Last Erred&rdquo;
state usually means that some data has been lost. Be sure to validate the
data on the volume after you repair it. For a UFS, run the <command>fsck</command> command
to validate the &ldquo;metadata&rdquo; (the structure of the file system).
Then, check the actual user data. (Practically, users will have to examine
their files.) A database or other application must have its own way of validating
its internal data structure.</para>
</listitem><listitem><para>Always check for state database replicas and hot spares when
you replace components. Any state database replica in an erred state should
be deleted before you replace the physical disk. The state database replica
should be added back before you enable the component. The same procedure applies
to hot spares.</para>
</listitem><listitem><para>During component replacement for a RAID-5 volume, data is
recovered in one of two ways. The data is recovered either from a hot spare
currently in use or from using the RAID-5 parity, when no hot spare is in
use.</para>
</listitem><listitem><para>When you replace a component for a RAID-1 volume, Solaris Volume Manager automatically
starts resynchronizing the new component with the rest of the volume. When
the resynchronization completes, the replaced component becomes readable and
writable. If the failed component has been replaced with data from a hot spare,
the hot spare is placed in the &ldquo;Available&rdquo; state and made available
for other hot spare replacements.</para>
</listitem><listitem><para>The new component must be large enough to replace the old
component.</para>
</listitem><listitem><para>As a precaution, back up all data before you replace &ldquo;Last
Erred&rdquo; devices.</para>
</listitem>
</itemizedlist>
</sect2>
</sect1>
</chapter>